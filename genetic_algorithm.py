# -*- coding: utf-8 -*-
"""GA code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CIEAP63w7YABjU0UbX5Wu3DGOEeZ7NIX

# Fitness function
"""

import os
import sys
import numpy as np
from statistics import mode, mean, median, stdev, variance, quantiles
import math
from tqdm import tqdm
import itertools
from functools import reduce
import operator
import pacman
import layout
import pacman
import multiAgents
import ghostAgents
import textDisplay


class GeneticAlgorithm:

    def __init__(self, 
                 n_genes,
                 n_iterations,
                 lchrom, 
                 pcross, 
                 pmutation, 
                 selection_type, 
                 popsize, 
                 n_elites,
                 data,
                 MAX_VALUE,
                 MIN_VALUE):
        

        self.n_genes = n_genes
        self.lchrom = lchrom
        self.popsize = popsize
        self.pcross = pcross
        self.pmutation = pmutation
        self.selection_type = selection_type
        self.n_iterations = n_iterations
        self.n_elites = n_elites
        self.data = data
        self.MAX_VALUE = MAX_VALUE
        self.MIN_VALUE = MIN_VALUE
        self.best_fitness_evolution = []
    
        pop = []
        while (len(pop) < self.popsize):
            # generate random chromosome a list of a random number between MIN_VALUE and MAX_VALUE where list length is n_genes
            chromosome = [np.random.randint(self.MIN_VALUE, self.MAX_VALUE) for _ in range(self.n_genes)]
            # if chromosome = set of 0 then generate new one
            if sum(chromosome) == 0:
                continue
            else:
                pop.append(chromosome)

        # Convert pop to list of solutions
        self.population = [tuple(x) for x in pop]
    


    def fitness_func(self, solution):
        # should maximize
        #  run pacman game with solution as weights
        def manhattanDistance(point1, point2):
            "Returns the Manhattan distance between points "
            return abs(point1[0] - point2[0]) + abs(point1[1] - point2[1])

        def customEvaluationFunction(self, currentGameState, action):
            a = solution[0]
            b = solution[1]
            c = solution[2]
            d = solution[3]
            e = solution[4]

            # Useful information you can extract from a GameState (pacman.py)
            successorGameState = currentGameState.generatePacmanSuccessor(action)
            newPos = successorGameState.getPacmanPosition()
            newFood = successorGameState.getFood()
            newGhostStates = successorGameState.getGhostStates()
            currentFood = currentGameState.getFood()

            # Initialize the heuristic value to zero
            heuristicValue = 0

            # Check if the game is over
            if successorGameState.isWin():
                return float("inf")

            if successorGameState.isLose():
                return float("-inf")

            # Compute the number of food pellets in the current and successor states
            numCurrentFood = currentFood.count()
            numSuccessorFood = newFood.count()
            min_food_distance = float("inf")
            sum_ghost_distances = 0
            newScaredTimes = [ghostState.scaredTimer for ghostState in newGhostStates]
            currentGhostPositions = currentGameState.getGhostPositions()

            # Compute the distance to the closest food pellet
            for food in newFood.asList():
                min_food_distance = min(min_food_distance, manhattanDistance(newPos, food))
            
            # Compute the distance to the closest ghost
            for ghost in newGhostStates:
                sum_ghost_distances += manhattanDistance(newPos, ghost.getPosition())
            
            # Compute the heuristic value
            score = a * (currentGameState.getNumFood() - successorGameState.getNumFood()) + b * (1 / min_food_distance) + c * (1 / sum_ghost_distances) + d * sum(newScaredTimes) + e * (1 if newPos in currentGhostPositions else 0)
            return score

        customAgent = type('CustomReflexAgent', (multiAgents.ReflexAgent,), {'evaluationFunction': customEvaluationFunction})
        game = self.data.rules.newGame(self.data.layout, customAgent(), self.data.ghostAgents, self.data.gameDisplay)
        # game.run()
        # score = game.state.getScore()
        # run it 5 times and take the average
        scores = []
        for i in range(5):
            game = self.data.rules.newGame(self.data.layout, customAgent(), self.data.ghostAgents, self.data.gameDisplay)
            game.run()
            scores.append(game.state.getScore())
        score = mean(scores)

        print("Individual: ", solution, "Score: ", score)
        return score

    def get_fitness_scores(self):
        scores = [self.fitness_func(ind) for ind in self.population]
        return np.array(scores)

    def __append_best_score(self, scores):
        best_score = np.max(scores)
        self.best_fitness_evolution.append(best_score)
        return 'Ok'
    
    def __ranking_selection(self, scores):
        ind = np.argsort(scores)
        best_ind = ind[-1]
        return best_ind


    def select(self, scores, selection_type):
        if selection_type not in ['ranking', 'roulette']:
            raise ValueError('Type should be ranking or tournament')

        if selection_type == 'ranking':
            ind = self.__ranking_selection(scores)
        elif selection_type == 'roulette':
            ind = self.__roulette_selection(scores)
        else:
            pass
        return ind

    def flip(self, p):
        return 1 if np.random.rand() < p else 0

    def __crossover(self, 
                    parent1, 
                    parent2, 
                    pcross,
                    lchrom):
        index = np.random.choice(range(1, lchrom)) 
        parent1 = list(parent1)
        parent2 = list(parent2)
        child1 = parent1[:index] + parent2[index:]
        child2 = parent2[:index] + parent1[index:]
        children = [tuple(child1), tuple(child2)]
        return children
    


    def __mutation(self, individual):

        index = np.random.choice(len(individual))
        
        # Convert individual to list so that can be modified
        individual_mod = list(individual)
        individual_mod[index] = np.random.randint(self.MIN_VALUE, self.MAX_VALUE)
        individual = tuple(individual_mod)

        return individual

    def optimize(self):

        for i in tqdm(range(self.n_iterations)):

            # calculate fitness score
            scores = self.get_fitness_scores()

            # choose the elites of the current population
            ind = np.argsort(scores)

            elites = [self.population[i] for i in ind[-self.n_elites:]]

            #append the elites to the population
            new_population = [tuple(elite) for elite in elites]

            # make selection
            j = self.n_elites
            while j <= self.popsize:
                # select parents from population
                mate1 = self.select(scores, self.selection_type)
                mate2 = self.select(scores, self.selection_type)


                mate1 = tuple(self.population[mate1])
                mate2 = tuple(self.population[mate2])

                if self.flip(self.pcross):
                    children = self.__crossover(mate1, mate2, self.pcross, self.lchrom)
                    children = [tuple(child) for child in children]
                else:
                    children = [mate1, mate2]
                
                if self.flip(self.pmutation):
                    children[0] = self.__mutation(children[0])

                if self.flip(self.pmutation):
                    children[1] = self.__mutation(children[1])

                if sum(tuple(children[0])) != 0:
                    new_population.append(tuple(children[0]))
                    j+=1
                
                if sum(tuple(children[1])) != 0:
                    new_population.append(tuple(children[1]))        
                    j+=1

            self.population = new_population

        # when n_iterations are over, fitness scores
        scores = self.get_fitness_scores()

        # append best score
        _ = self.__append_best_score(scores)

        # get the result wher he results is the best
        best_score_ind =np.argpartition(scores, 0)[0]
    
        best_solution = self.population[best_score_ind]

        return (best_solution, self.best_fitness_evolution[-1])

def default(str):
    return str + ' [Default: %default]'

class Data:
    def __init__(self, layout, rules, gameDisplay, ghostAgents):
        self.layout = layout
        self.rules = rules
        self.gameDisplay = gameDisplay
        self.ghostAgents = ghostAgents

def main( argv ):
    from optparse import OptionParser
    usageStr = """
    USAGE:      python genetic_algorithm.py <options>
    EXAMPLES:   (1) python genetic_algorithm.py -l smallClassic -k 10
                    - starts genetic algorithm on a small layout with 10 ghosts agents
    """
    parser = OptionParser(usageStr)
    parser.add_option('-k', '--numGhosts', dest='numGhosts', type='int',
                      help=default('the number of ghosts to run'), metavar='GHOSTS', default=10)
    parser.add_option('-l', '--layout', dest='layout',
                      help=default('the LAYOUT_FILE from which to load the map layout'),
                      metavar='LAYOUT_FILE', default='smallClassic')
    options, otherjunk = parser.parse_args(argv)
    if len(otherjunk) != 0:
        raise Exception('Command line input not understood: ' + str(otherjunk))
    
    used_layout = layout.getLayout(options.layout)
    k = options.numGhosts

    rules = pacman.ClassicGameRules()
    gameDisplay = textDisplay.PacmanGraphics()
    rules.quiet = True
    
    data = Data(used_layout, rules, gameDisplay, [ghostAgents.DirectionalGhost(i+1) for i in range(k)])
    # customAgent = type('CustomReflexAgent', (multiAgents.ReflexAgent,), {'evaluationFunction': customEvaluationFunction})
    # game = rules.newGame(data.layout, customAgent(), data.ghostAgents, data.gameDisplay)
    # game.run()

    
    ga = GeneticAlgorithm(
        n_genes = 5,
        n_iterations = 20,
        lchrom = 5,
        pcross = 0.8, 
        pmutation = 0.2,
        selection_type = 'ranking', 
        popsize = 20,
        n_elites = 2,
        data = data,
        MAX_VALUE = 100,
        MIN_VALUE = -100,
    )

    best_solution, best_fitness = ga.optimize()
    print('\nBest solution:\t', best_solution)
    print('\nBest Fitness:\t', round(best_fitness))
    print("\n\n----------------------------------\n\n")

if __name__ == "__main__":
    main( sys.argv[1:] )
